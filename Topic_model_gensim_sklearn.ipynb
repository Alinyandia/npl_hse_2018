{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основаная задача - **построить хорошую тематическую модель с интерпретируемыми топиками с помощью LDA в gensim и NMF в sklearn**.\n",
    "\n",
    "\n",
    "1) сделайте нормализацию (если pymorphy2 работает долго используйте mystem или попробуйте установить быструю версию - `pip install pymorphy2[fast]`, можно использовать какой-то другой токенизатор); \n",
    "\n",
    "2) добавьте нграммы (в тетрадке есть закомменченая ячейка с Phrases,  можно также попробовать другие способы построить нграммы); \n",
    "\n",
    "3) сделайте хороший словарь (отфильтруйте слишком частотные и редкие слова, попробуйте удалить стоп-слова); \n",
    "\n",
    "4) постройте несколько LDA моделей (переберите количество тем, можете поменять eta, alpha, passes), если получаются плохие темы, поработайте дополнительно над предобработкой и словарем; \n",
    "\n",
    "5) для самой хорошей модели в отдельной ячейке напечатайте 3 хороших (на ваш вкус) темы;\n",
    "\n",
    "6) между словарем и обучением модели добавьте tfidf (`gensim.models.TfidfModel(corpus, id2word=dictionary); corpus = tfidf[corpus]`);\n",
    "\n",
    "7) повторите пункт 4 на преобразованном корпусе;\n",
    "\n",
    "8) в отдельной ячейке опишите как изменилась модель (приведите несколько тем, которые стали лучше или хуже, или которых раньше вообще не было; можно привести значения перплексии и когерентности для обеих моделей)\n",
    "\n",
    "9) проделайте такие же действия для NMF (образец в конце тетрадки), для построения словаря воспользуйтесь возможностями Count или Tfidf Vectorizer (попробуйте другие значение max_features, min_df, max_df, сделайте нграмы через ngram_range, если хватает памяти), попробуйте такие же количества тем\n",
    "\n",
    "10) в отдельной ячейки напечатайте таблицу с темами лучшей NMF модели, сравните их с теми, что получились в LDA.\n",
    "\n",
    "Сохраните тетрадку с экспериментами и положите её на гитхаб, ссылку на неё укажите в форме.\n",
    "\n",
    "**Оцениваться будут главным образом пункты 5, 8 и 10. (2, 3, 2 баллов соответственно). Чтобы заработать остальные 3 балла, нужно хотя бы немного изменить мой код на промежуточных этапах (добавить что-то, указать другие параметры и т.д). **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import json\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import pyLDAvis.gensim\n",
    "import string\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "stops = set(stopwords.words('russian'))\n",
    "stops |= set(stopwords.words('english'))\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('russian')) | {'gt',}\n",
    "def remove_tags(text):\n",
    "    return re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "def normalize(words):\n",
    "    norm_words = [morph.parse(word)[0].normal_form for word in words if len(set(word)) > 1]\n",
    "    return norm_words\n",
    "\n",
    "def opt_normalize(texts, top=None):\n",
    "    uniq = Counter()\n",
    "    for text in texts:\n",
    "        uniq.update(text)\n",
    "    \n",
    "    norm_uniq = {word:morph.parse(word)[0].normal_form for word, _ in uniq.most_common(top)}\n",
    "    \n",
    "    norm_texts = []\n",
    "    for text in texts:\n",
    "        \n",
    "        norm_words = [norm_uniq.get(word) for word in text]\n",
    "        norm_words = [word for word in norm_words if word and word not in stops]\n",
    "        norm_texts.append(norm_words)\n",
    "        \n",
    "    return norm_texts\n",
    "\n",
    "def tokenize(text):\n",
    "    words = [word.strip(string.punctuation) for word in text.split()]\n",
    "    words = [word for word in words if word]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДЗ начинаю отсюда:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) сделайте нормализацию (если pymorphy2 работает долго используйте mystem или попробуйте установить быструю версию - pip install pymorphy2[fast], можно использовать какой-то другой токенизатор);\n",
    "\n",
    "2) добавьте нграммы (в тетрадке есть закомменченая ячейка с Phrases, можно также попробовать другие способы построить нграммы);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем 4 тыс статьи с Хабра. Это мало для хорошей тематической модели, но иначе у нас просто ничего не обучится за семинар."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В текстах есть тэги. Потрем их. Ещё токенизируем самым простым способом и нормализуем Pymorphy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 s, sys: 1.09 s, total: 5.09 s\n",
      "Wall time: 6.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "texts = open('/Users/alinashaymardanova/Downloads/habr_texts.txt').read().splitlines()\n",
    "texts = [tokenize(remove_tags(text.lower())) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 17s, sys: 1.5 s, total: 2min 19s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "texts = open('/Users/alinashaymardanova/Downloads/habr_texts.txt').read().splitlines()\n",
    "texts = [normalize(tokenize(text.lower())) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.54 s, sys: 761 ms, total: 10.3 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "texts = open('/Users/alinashaymardanova/Downloads/habr_texts.txt').read().splitlines()\n",
    "texts = opt_normalize([tokenize(remove_tags(text.lower())) for text in texts], 30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавим в список стоп-слов lt, будем использовать mysem (вообще, опираясь на свою практику, могку сказать, что в большинстве случаев он работает лучше)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = set(stopwords.words('russian')) | {'gt',} | {'lt',}\n",
    "mystem = Mystem()\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub('\\s{2,}', '', text)\n",
    "    text = re.sub('[^a-zA-ZА-Яа-я]', ' ', text)\n",
    "    tokens = mystem.lemmatize(text)\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords \\\n",
    "              and token != ' ' and token.strip() not in (punctuation + '«»—…“”*№–')]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = open('/Users/alinashaymardanova/Downloads/habr_texts.txt').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [preprocessing(remove_tags(text.lower())) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тематическое моделирование в gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделей нужно сделать словарь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictinary = gensim.corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictinary.filter_extremes(no_above=0.3)\n",
    "dictinary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(24527 unique tokens: ['a', 'address', 'api', 'architecture', 'argumentnullexception']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictinary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем наши тексты в мешки слов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictinary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ?gensim.models.LdaMulticore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 1.02 s, total: 1min 5s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#lda = gensim.models.LdaMulticore(corpus, 100, id2word=dictinary, passes=5, eta='auto', iterations=10, workers=8)\n",
    "lda = gensim.models.LdaModel(corpus, id2word=dictinary, passes=10, num_topics=10, eta='auto', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = gensim.models.CoherenceModel(model=lda, \n",
    "                                                   texts=texts, \n",
    "                                                   dictionary=dictinary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = []\n",
    "for topic_id, topic in lda.show_topics(num_topics=100, formatted=False):\n",
    "    topic = [word for word, _ in topic]\n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = gensim.models.CoherenceModel(topics=topics, \n",
    "                                                   texts=texts, \n",
    "                                                   dictionary=dictinary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63765170056602671"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-граммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# для нграммов\n",
    "ph = gensim.models.Phrases(texts, scoring='npmi', threshold=0.4) # threshold можно подбирать\n",
    "p = gensim.models.phrases.Phraser(ph)\n",
    "ngrammed_texts = p[texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictinary = gensim.corpora.Dictionary(ngrammed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictinary.filter_extremes(no_above=0.3)\n",
    "dictinary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictinary.doc2bow(text) for text in ngrammed_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.1 s, sys: 943 ms, total: 51 s\n",
      "Wall time: 50.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#lda = gensim.models.LdaMulticore(corpus, id2word=dictinary, passes=5, eta='auto', iterations=10) \n",
    "lda = gensim.models.LdaModel(corpus, id2word=dictinary, passes=10, num_topics=10, eta='auto', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coherence_model_lda = gensim.models.CoherenceModel(model=lda, \n",
    "                                                   texts=texts, \n",
    "                                                   dictionary=dictinary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = []\n",
    "for topic_id, topic in lda.show_topics(num_topics=100, formatted=False):\n",
    "    topic = [word for word, _ in topic]\n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coherence_model_lda = gensim.models.CoherenceModel(topics=topics, \n",
    "                                                   texts=ngrammed_texts, \n",
    "                                                   dictionary=dictinary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38807584882283669"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Для самой хорошей модели в отдельной ячейке напечатаем 3 хороших темы;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         объект\n",
       "1       значение\n",
       "2        элемент\n",
       "3           блок\n",
       "4          метод\n",
       "5       алгоритм\n",
       "6          точка\n",
       "7         строка\n",
       "8    изображение\n",
       "9       текстура\n",
       "Name: Тема 04, dtype: object"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         пациент\n",
       "1            мозг\n",
       "2          клетка\n",
       "3          ученый\n",
       "4     заболевание\n",
       "5    исследование\n",
       "6         болезнь\n",
       "7            врач\n",
       "8         лечение\n",
       "9             ген\n",
       "Name: Тема 18, dtype: object"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  диск\n",
       "1                сервер\n",
       "2           виртуальный\n",
       "3                память\n",
       "4             резервный\n",
       "5                машина\n",
       "6                   ssd\n",
       "7    производительность\n",
       "8             процессор\n",
       "9                    вм\n",
       "Name: Тема 20, dtype: object"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, что выглядит неплохо:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = gensim.models.TfidfModel(corpus, id2word=dictinary)\n",
    "corpus = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = gensim.models.LdaModel(corpus, id2word=dictinary, passes=10, num_topics=100, eta='auto', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coherence_model_lda = gensim.models.CoherenceModel(model=lda, \n",
    "                                                   texts=texts, \n",
    "                                                   dictionary=dictinary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = []\n",
    "for topic_id, topic in lda.show_topics(num_topics=100, formatted=False):\n",
    "    topic = [word for word, _ in topic]\n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coherence_model_lda = gensim.models.CoherenceModel(topics=topics, \n",
    "                                                   texts=ngrammed_texts, \n",
    "                                                   dictionary=dictinary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tfidf не улучшил качество работы моделей, так как в топ попадает много слов, принадлежащих только одной узкой категории (названия функций, переменных и др.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разложение матриц в sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stexts = [' '.join(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=25000, min_df=5, max_df=0.3, lowercase=False)\n",
    "X = vectorizer.fit_transform(stexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = NMF(n_components=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=30, random_state=None, shuffle=False, solver='cd',\n",
       "  tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nmf_topics(model, n_top_words):\n",
    "    \n",
    "    #id слов.\n",
    "    feat_names = vectorizer.get_feature_names()\n",
    "    \n",
    "    word_dict = {};\n",
    "    for i in range(30):\n",
    "        \n",
    "        #топ n слов для темы.\n",
    "        words_ids = model.components_[i].argsort()[:-n_top_words - 1:-1]\n",
    "        words = [feat_names[key] for key in words_ids]\n",
    "        word_dict['Тема ' + '{:02d}'.format(i+1)] = words;\n",
    "    \n",
    "    return pd.DataFrame(word_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Тема 01</th>\n",
       "      <th>Тема 02</th>\n",
       "      <th>Тема 03</th>\n",
       "      <th>Тема 04</th>\n",
       "      <th>Тема 05</th>\n",
       "      <th>Тема 06</th>\n",
       "      <th>Тема 07</th>\n",
       "      <th>Тема 08</th>\n",
       "      <th>Тема 09</th>\n",
       "      <th>Тема 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Тема 21</th>\n",
       "      <th>Тема 22</th>\n",
       "      <th>Тема 23</th>\n",
       "      <th>Тема 24</th>\n",
       "      <th>Тема 25</th>\n",
       "      <th>Тема 26</th>\n",
       "      <th>Тема 27</th>\n",
       "      <th>Тема 28</th>\n",
       "      <th>Тема 29</th>\n",
       "      <th>Тема 30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>продукт</td>\n",
       "      <td>if</td>\n",
       "      <td>игра</td>\n",
       "      <td>объект</td>\n",
       "      <td>файл</td>\n",
       "      <td>android</td>\n",
       "      <td>устройство</td>\n",
       "      <td>css</td>\n",
       "      <td>космический</td>\n",
       "      <td>атака</td>\n",
       "      <td>...</td>\n",
       "      <td>печать</td>\n",
       "      <td>центр</td>\n",
       "      <td>public</td>\n",
       "      <td>бот</td>\n",
       "      <td>сайт</td>\n",
       "      <td>звук</td>\n",
       "      <td>камера</td>\n",
       "      <td>товар</td>\n",
       "      <td>this</td>\n",
       "      <td>российский</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>клиент</td>\n",
       "      <td>int</td>\n",
       "      <td>игрок</td>\n",
       "      <td>значение</td>\n",
       "      <td>php</td>\n",
       "      <td>google</td>\n",
       "      <td>смартфон</td>\n",
       "      <td>js</td>\n",
       "      <td>спутник</td>\n",
       "      <td>безопасность</td>\n",
       "      <td>...</td>\n",
       "      <td>принтер</td>\n",
       "      <td>дата</td>\n",
       "      <td>string</td>\n",
       "      <td>telegram</td>\n",
       "      <td>реклама</td>\n",
       "      <td>сигнал</td>\n",
       "      <td>видео</td>\n",
       "      <td>скидка</td>\n",
       "      <td>react</td>\n",
       "      <td>страна</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>сотрудник</td>\n",
       "      <td>amp</td>\n",
       "      <td>игровой</td>\n",
       "      <td>элемент</td>\n",
       "      <td>http</td>\n",
       "      <td>ios</td>\n",
       "      <td>аккумулятор</td>\n",
       "      <td>javascript</td>\n",
       "      <td>орбита</td>\n",
       "      <td>уязвимость</td>\n",
       "      <td>...</td>\n",
       "      <td>станок</td>\n",
       "      <td>инфраструктура</td>\n",
       "      <td>void</td>\n",
       "      <td>сообщение</td>\n",
       "      <td>страница</td>\n",
       "      <td>усилитель</td>\n",
       "      <td>vr</td>\n",
       "      <td>магазин</td>\n",
       "      <td>div</td>\n",
       "      <td>россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>бизнес</td>\n",
       "      <td>return</td>\n",
       "      <td>играть</td>\n",
       "      <td>блок</td>\n",
       "      <td>docker</td>\n",
       "      <td>мобильный</td>\n",
       "      <td>телефон</td>\n",
       "      <td>react</td>\n",
       "      <td>ракета</td>\n",
       "      <td>злоумышленник</td>\n",
       "      <td>...</td>\n",
       "      <td>мм</td>\n",
       "      <td>услуга</td>\n",
       "      <td>new</td>\n",
       "      <td>bot</td>\n",
       "      <td>контент</td>\n",
       "      <td>частота</td>\n",
       "      <td>движение</td>\n",
       "      <td>цена</td>\n",
       "      <td>props</td>\n",
       "      <td>налог</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>менеджер</td>\n",
       "      <td>count</td>\n",
       "      <td>vr</td>\n",
       "      <td>метод</td>\n",
       "      <td>сервер</td>\n",
       "      <td>app</td>\n",
       "      <td>usb</td>\n",
       "      <td>angular</td>\n",
       "      <td>марс</td>\n",
       "      <td>пароль</td>\n",
       "      <td>...</td>\n",
       "      <td>материал</td>\n",
       "      <td>облачный</td>\n",
       "      <td>class</td>\n",
       "      <td>чат</td>\n",
       "      <td>браузер</td>\n",
       "      <td>наушник</td>\n",
       "      <td>регистратор</td>\n",
       "      <td>распродажа</td>\n",
       "      <td>компонент</td>\n",
       "      <td>рубль</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>заказчик</td>\n",
       "      <td>std</td>\n",
       "      <td>персонаж</td>\n",
       "      <td>алгоритм</td>\n",
       "      <td>sudo</td>\n",
       "      <td>layout</td>\n",
       "      <td>датчик</td>\n",
       "      <td>веб</td>\n",
       "      <td>аппарат</td>\n",
       "      <td>защита</td>\n",
       "      <td>...</td>\n",
       "      <td>печатать</td>\n",
       "      <td>оборудование</td>\n",
       "      <td>класс</td>\n",
       "      <td>api</td>\n",
       "      <td>клиент</td>\n",
       "      <td>искажение</td>\n",
       "      <td>реальность</td>\n",
       "      <td>покупатель</td>\n",
       "      <td>function</td>\n",
       "      <td>закон</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>crm</td>\n",
       "      <td>null</td>\n",
       "      <td>unity</td>\n",
       "      <td>точка</td>\n",
       "      <td>nginx</td>\n",
       "      <td>устройство</td>\n",
       "      <td>дисплей</td>\n",
       "      <td>vue</td>\n",
       "      <td>планета</td>\n",
       "      <td>устройство</td>\n",
       "      <td>...</td>\n",
       "      <td>производство</td>\n",
       "      <td>облако</td>\n",
       "      <td>private</td>\n",
       "      <td>message</td>\n",
       "      <td>домен</td>\n",
       "      <td>звуковой</td>\n",
       "      <td>blackvue</td>\n",
       "      <td>пятница</td>\n",
       "      <td>const</td>\n",
       "      <td>рынок</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>программист</td>\n",
       "      <td>const</td>\n",
       "      <td>steam</td>\n",
       "      <td>строка</td>\n",
       "      <td>скрипт</td>\n",
       "      <td>swift</td>\n",
       "      <td>ноутбук</td>\n",
       "      <td>html</td>\n",
       "      <td>земля</td>\n",
       "      <td>вредоносный</td>\n",
       "      <td>...</td>\n",
       "      <td>деталь</td>\n",
       "      <td>сервис</td>\n",
       "      <td>name</td>\n",
       "      <td>мессенджер</td>\n",
       "      <td>рекламный</td>\n",
       "      <td>музыка</td>\n",
       "      <td>виртуальный</td>\n",
       "      <td>покупка</td>\n",
       "      <td>return</td>\n",
       "      <td>доход</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>опыт</td>\n",
       "      <td>char</td>\n",
       "      <td>движок</td>\n",
       "      <td>изображение</td>\n",
       "      <td>name</td>\n",
       "      <td>play</td>\n",
       "      <td>корпус</td>\n",
       "      <td>браузер</td>\n",
       "      <td>луна</td>\n",
       "      <td>сеть</td>\n",
       "      <td>...</td>\n",
       "      <td>изделие</td>\n",
       "      <td>цод</td>\n",
       "      <td>return</td>\n",
       "      <td>канал</td>\n",
       "      <td>google</td>\n",
       "      <td>акустика</td>\n",
       "      <td>кадр</td>\n",
       "      <td>заказ</td>\n",
       "      <td>dom</td>\n",
       "      <td>налоговый</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>тестирование</td>\n",
       "      <td>else</td>\n",
       "      <td>жанр</td>\n",
       "      <td>текстура</td>\n",
       "      <td>file</td>\n",
       "      <td>view</td>\n",
       "      <td>батарея</td>\n",
       "      <td>es</td>\n",
       "      <td>станция</td>\n",
       "      <td>доступ</td>\n",
       "      <td>...</td>\n",
       "      <td>металл</td>\n",
       "      <td>провайдер</td>\n",
       "      <td>var</td>\n",
       "      <td>телегр</td>\n",
       "      <td>сервер</td>\n",
       "      <td>акустический</td>\n",
       "      <td>ip</td>\n",
       "      <td>акция</td>\n",
       "      <td>class</td>\n",
       "      <td>ооо</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Тема 01 Тема 02   Тема 03      Тема 04 Тема 05     Тема 06  \\\n",
       "0       продукт      if      игра       объект    файл     android   \n",
       "1        клиент     int     игрок     значение     php      google   \n",
       "2     сотрудник     amp   игровой      элемент    http         ios   \n",
       "3        бизнес  return    играть         блок  docker   мобильный   \n",
       "4      менеджер   count        vr        метод  сервер         app   \n",
       "5      заказчик     std  персонаж     алгоритм    sudo      layout   \n",
       "6           crm    null     unity        точка   nginx  устройство   \n",
       "7   программист   const     steam       строка  скрипт       swift   \n",
       "8          опыт    char    движок  изображение    name        play   \n",
       "9  тестирование    else      жанр     текстура    file        view   \n",
       "\n",
       "       Тема 07     Тема 08      Тема 09        Тема 10     ...      \\\n",
       "0   устройство         css  космический          атака     ...       \n",
       "1     смартфон          js      спутник   безопасность     ...       \n",
       "2  аккумулятор  javascript       орбита     уязвимость     ...       \n",
       "3      телефон       react       ракета  злоумышленник     ...       \n",
       "4          usb     angular         марс         пароль     ...       \n",
       "5       датчик         веб      аппарат         защита     ...       \n",
       "6      дисплей         vue      планета     устройство     ...       \n",
       "7      ноутбук        html        земля    вредоносный     ...       \n",
       "8       корпус     браузер         луна           сеть     ...       \n",
       "9      батарея          es      станция         доступ     ...       \n",
       "\n",
       "        Тема 21         Тема 22  Тема 23     Тема 24    Тема 25       Тема 26  \\\n",
       "0        печать           центр   public         бот       сайт          звук   \n",
       "1       принтер            дата   string    telegram    реклама        сигнал   \n",
       "2        станок  инфраструктура     void   сообщение   страница     усилитель   \n",
       "3            мм          услуга      new         bot    контент       частота   \n",
       "4      материал        облачный    class         чат    браузер       наушник   \n",
       "5      печатать    оборудование    класс         api     клиент     искажение   \n",
       "6  производство          облако  private     message      домен      звуковой   \n",
       "7        деталь          сервис     name  мессенджер  рекламный        музыка   \n",
       "8       изделие             цод   return       канал     google      акустика   \n",
       "9        металл       провайдер      var      телегр     сервер  акустический   \n",
       "\n",
       "       Тема 27     Тема 28    Тема 29     Тема 30  \n",
       "0       камера       товар       this  российский  \n",
       "1        видео      скидка      react      страна  \n",
       "2           vr     магазин        div      россия  \n",
       "3     движение        цена      props       налог  \n",
       "4  регистратор  распродажа  компонент       рубль  \n",
       "5   реальность  покупатель   function       закон  \n",
       "6     blackvue     пятница      const       рынок  \n",
       "7  виртуальный     покупка     return       доход  \n",
       "8         кадр       заказ        dom   налоговый  \n",
       "9           ip       акция      class         ооо  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nmf_topics(model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.473381463715747"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reconstruction_err_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А если взять другие параметры?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nvectorizer = TfidfVectorizer(max_features=30000, min_df=5, max_df=0.5)\n",
    "nX = nvectorizer.fit_transform(stexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=30, random_state=None, shuffle=False, solver='cd',\n",
       "  tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmodel = NMF(n_components=30)\n",
    "nmodel.fit(nX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.130540306134954"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmodel.reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nvectorizer = TfidfVectorizer(max_features=20000, min_df=5, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nX = nvectorizer.fit_transform(stexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmodel = NMF(n_components=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=30, random_state=None, shuffle=False, solver='cd',\n",
       "  tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmodel.fit(nX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.076327001679907"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmodel.reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nvectorizer = TfidfVectorizer(max_features=10000, min_df=5, max_df=0.5)\n",
    "nX = nvectorizer.fit_transform(stexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmodel = NMF(n_components=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=30, random_state=None, shuffle=False, solver='cd',\n",
       "  tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmodel.fit(nX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.63107858531545"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmodel.reconstruction_err_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем, что LDA показывает себя хорошо, так как видно, что он выбирает хорошие ключевые слова. Однако насмотря на это, всё равно в итоговыую выборку попадает очень много мусора и не ключевых слов. При NMF шума меньше. Из-за этого, в LDA сложно выбрать хорошие примеры:( Таким образом, NMF работает лучше:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
